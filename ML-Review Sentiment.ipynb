{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Sentiment:\n",
    "    Negative = 'Sorry for the disappointment'\n",
    "    Positive = 'Thanks, It means alot'\n",
    "    Netural = \"Ok, we'll look into it\"\n",
    "class Review:\n",
    "    def __init__(self,text,score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "        \n",
    "    def get_sentiment(self):\n",
    "        if self.score <=2:\n",
    "            return Sentiment.Negative\n",
    "        elif self.score >2 and self.score <=3:\n",
    "            return Sentiment.Netural\n",
    "        else:\n",
    "            return Sentiment.Positive\n",
    "#  We have break the values individually based on the sentiment and make it equal dataset for creating the model       \n",
    "class ReviewContainer:\n",
    "    def __init__(self,reviews):\n",
    "        self.reviews = reviews\n",
    "        \n",
    "    def get_text(self):\n",
    "# Splitting the text data from the reviews dataset        \n",
    "        return [x.text for x in self.reviews]\n",
    "    \n",
    "    def get_comment(self):\n",
    "# Splitting the sentiment data from the reviews dataset        \n",
    "        return [x.sentiment for x in self.reviews]\n",
    "# This one helps to split the values based on the sentiment\n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x: x.sentiment == Sentiment.Negative,self.reviews))\n",
    "        positive = list(filter(lambda x: x.sentiment == Sentiment.Positive,self.reviews))\n",
    "        Neutral = list(filter(lambda x: x.sentiment == Sentiment.Netural,self.reviews))\n",
    " \n",
    "# we are making it equal number of positive values to negative\n",
    "\n",
    "        positive_shrunk = positive[:len(negative)]\n",
    "        self.reviews = negative+positive_shrunk\n",
    "        random.shuffle(self.reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_name = 'Books_small_10000.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for file in f:\n",
    "        review = json.loads(file)\n",
    "        reviews.append(Review(review['reviewText'],review['overall']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "Thanks, It means alot\n"
     ]
    }
   ],
   "source": [
    "print(reviews[4].score)\n",
    "print(reviews[5].sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reviewerID': 'A1EZD7IJOOAF6S',\n",
       " 'asin': '0956998569',\n",
       " 'reviewerName': 'Amazon Customer',\n",
       " 'helpful': [1, 1],\n",
       " 'reviewText': \"Highly recommend this entire trilogy. It is very well written and held me in suspense and kept me reading.  Even with the same old young girl heroine who goes head strong and hell bent on saving the new world, id tecommend this book to dystopian fiction fans!  Not overdone, thankfully! A fesw situations made it feel like I've read this same plot before....but these were well thought out and much better written!  This authr has a gift a d I will be looking forward to reading more of ber work.\",\n",
       " 'overall': 4.0,\n",
       " 'summary': 'truly enjoyed',\n",
       " 'unixReviewTime': 1402358400,\n",
       " 'reviewTime': '06 10, 2014'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training,test = train_test_split(reviews,test_size=0.33,random_state=42)\n",
    "\n",
    "# Here we are splitting the training and test data based on the ReviewContainer class\n",
    "train_cont=ReviewContainer(training)\n",
    "test_cont = ReviewContainer(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "From the f1_score values still the negative prediction score is very low as compared to positive.\n",
    "Which is due to high positive sentiments in the test_y dataset.\n",
    "To improve the f1_score we are making the test data also evenly distributed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cont.evenly_distribute()\n",
    "train_x = train_cont.get_text()\n",
    "train_y = train_cont.get_comment()\n",
    "\n",
    "test_cont.evenly_distribute()\n",
    "test_x = test_cont.get_text()\n",
    "test_y = test_cont.get_comment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n",
      "436\n"
     ]
    }
   ],
   "source": [
    "print(train_y.count(Sentiment.Positive))\n",
    "print(train_y.count(Sentiment.Negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n",
      "208\n"
     ]
    }
   ],
   "source": [
    "print(test_y.count(Sentiment.Positive))\n",
    "print(test_y.count(Sentiment.Negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found this book to be very interesting. Started and didn't want to put it down. Enjoyed it very much. Good ending.\n",
      "Thanks, It means alot\n",
      "Recommended by a friend as &#34;one of the best books I have read.&#34;  I would not go that far but it is a page turner and very touching story.  Delightful read.\n",
      "Thanks, It means alot\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0])\n",
    "print(train_y[0])\n",
    "\n",
    "print(test_x[4])\n",
    "print(test_y[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<416x8906 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 24092 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #This another type of vectorizer\n",
    "\n",
    "# vectorizer = CountVectorizer()\n",
    "vectorizer = TfidfVectorizer()\n",
    "# Converting string to binary machine understanding\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "\n",
    "test_x_vectors = vectorizer.transform(test_x)\n",
    "# print(train_x_vectors[0].get_feature_names())\n",
    "# It helps to get the list of words in the training data\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "train_x_vectors[0]\n",
    "test_x_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<872x8906 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 53647 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LOVE THE SERIES OF BOOKS WITH HARRY HOLE. THEY ARE REALLY EXCITING AND A LITTLE BIT DARK. HE IS A GREAT AUTHOR. DON'T MISS ANY OF HIS BOOKS.\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sure all the sanctioned words are in there, but how to find them while in game?  There is no search feature and who has time to scroll through the whole alphabet to check your hoped for word?  It takes so long!  Your friends will chuck you out of the game.  Oh, yes they will. Later, when you have no more friends to play with you can scroll and scroll and scroll to use up your now desolate life.  :P\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Thanks, It means alot'], dtype='<U28')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "clf_svm.fit(train_x_vectors,train_y)\n",
    "\n",
    "print(test_x[0])\n",
    "\n",
    "clf_svm.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This odd and pretentious novel is based on the true case of an innocent man who falsely confessed to a series of homicides. The nation is on edge in the wake of a series of mysterious disappearances. The targets, all older, solitary sorts, vanish and their presumed abductor leaves nary a clue but for a marked playing card. Oda Sotatsu is a young man living a life both unfulfilling and uninteresting. That is until he meets a troublesome couple, the supposedly charismatic Sato Kakuzo and his girlfriend, the alluring,Jito Joo. Clearly disturbed, they play games and place wagers where the loser has to physically harm himself. They attach to Oda, inducing him into  a wager after plying him with alcohol. After losing the game, he signs a detailed confession admitting culpability in the disappearances. Joo delivers the confession to the police and Oda is soon arrested, imprisoned, abused, tried and convicted. He is subsequently sentenced to death by hanging and executed, remaining silent throughout the whole ordeal. Enter journalist Bell who is drawn to the mystery while still pondering the dissolution of his marriage. The book is largely a series of transcripts of the bewildered and dismayed family members, interrogations, newspaper coverage of the trial and finally with Joo and Kakuzo.This book felt half baked.  The transcript style of telling the story contributed to the unfinished feel. The story lacked suspense and mystery but it was far from a searing condemnation of the Japanese justice system. Obviously a confession is the gold standard in Japanese jurisprudence because there was really no evidence that a crime was committed, much less that Oda committed one. Oda's behavior and refusal to speak or defend himself was inexplicable, even if one factors in traditional concepts of honor. Joo and Kakuzo fail to trigger the fascination that classically destructive couples do. They are not Sid and Nancy, Bonnie and Clyde or even Romeo and Juliet. They are boring and shallow. The ending is a total disappointment making the sacrifice and I use the term loosely of Oda's life stupid and meaningless.This could have been an examination of false confessions or an indictment of the death penalty. It could have been a haunting character study that addressed  the relevance of honor in modern society. The spare writing contributed to a dream like atmosphere but muted even the horror of the gallows. Oda remained a cipher. Despite the cool cover, this book was no more than two hundred plus pages of self indulgence. Pass.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Sorry for the disappointment'], dtype='<U28')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors,train_y)\n",
    "\n",
    "print(test_x[22])\n",
    "clf_dec.predict(test_x_vectors[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOVE THE SERIES OF BOOKS WITH HARRY HOLE. THEY ARE REALLY EXCITING AND A LITTLE BIT DARK. HE IS A GREAT AUTHOR. DON'T MISS ANY OF HIS BOOKS.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Thanks, It means alot'], dtype='<U28')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(train_x_vectors,train_y)\n",
    "\n",
    "print(test_x[98])\n",
    "clf_log.predict(test_x_vectors[98])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6225961538461539\n",
      "0.8052884615384616\n",
      "0.8076923076923077\n"
     ]
    }
   ],
   "source": [
    "print(clf_dec.score(test_x_vectors,test_y))\n",
    "print(clf_log.score(test_x_vectors,test_y))\n",
    "print(clf_svm.score(test_x_vectors,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80582524 0.         0.80952381]\n",
      "[0.62529833 0.         0.61985472]\n",
      "[0.80291971 0.         0.80760095]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1464: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# f1_score of svm model\n",
    "print(f1_score(test_y,clf_svm.predict(test_x_vectors),average=None,labels=[Sentiment.Positive,Sentiment.Netural,Sentiment.Negative]))\n",
    "# f1_score of decision tree .\n",
    "print(f1_score(test_y,clf_dec.predict(test_x_vectors),average=None,labels=[Sentiment.Positive,Sentiment.Netural,Sentiment.Negative]))\n",
    "# f1_score of Logistic reg\n",
    "print(f1_score(test_y,clf_log.predict(test_x_vectors),average=None,labels=[Sentiment.Positive,Sentiment.Netural,Sentiment.Negative]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Thanks, It means alot'], dtype='<U28')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = ['This book is much super']\n",
    "# test_set = [\"this is the best book\",'This is the worst than ever','I expected more but you have disappointed me','']\n",
    "new_set = vectorizer.transform(test_set)\n",
    "# print(vectorizer.get_feature_names())\n",
    "# print(new_set[0])\n",
    "\n",
    "clf_svm.predict(new_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': (1, 4, 8, 16, 32), 'kernel': ('linear', 'rbf')})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameter = {'kernel':('linear','rbf'),'C':(1,4,8,16,32)}\n",
    "\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc,parameter,cv=5)\n",
    "\n",
    "clf.fit(train_x_vectors,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8052884615384616"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_x_vectors,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# here we can save the model. So we can call anytime\n",
    "with open('./Machine Models/Review_sentiment.pkl','wb') as f:\n",
    "    pickle.dump(clf,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Machine Models/Review_sentiment.pkl','rb') as f:\n",
    "    load_clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For me this book was just two and a half stars. The characters took too long to get together with silly misunderstandings. When they finally got together she runs away from him with another misunderstanding. The end felt too rushed. I was annoyed with the second book when they were little together because of the tour. I thought they would be together more in the last book and got disappointed when that didn't happened.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Sorry for the disappointment'], dtype='<U28')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_x[67])\n",
    "load_clf.predict(test_x_vectors[67])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
